{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeXpression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmnFq2kT8OpLDH54eWNE7c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63OvI0zGNhey"
      },
      "source": [
        "Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7oRS1MmNj60",
        "outputId": "775fba62-3e66-4362-da5a-faaf070707f2"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path = '/content/gdrive/MyDrive/DeXpression'\n",
        "os.chdir(path)\n",
        "\n",
        "DATA_FOLDER = '/content/gdrive/MyDrive/DeXpression/dataset/CK+48'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu3MccCA9dX5"
      },
      "source": [
        "Standard imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ga62fJx82jX"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.nn import Module, Conv2d, MaxPool2d, Linear, ReLU, LogSoftmax\n",
        "\n",
        "from torch.nn import LayerNorm, BatchNorm2d, Dropout\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bklaM2Vy9g_2"
      },
      "source": [
        "#DeXpression model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaeCVAjGJa-X"
      },
      "source": [
        "Transfer to GPU (if applicable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JG-A9mBJahp"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da_kHqAa9gjR"
      },
      "source": [
        "class DeXpression(Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(DeXpression, self).__init__()\n",
        "\n",
        "    # block-1\n",
        "    self.conv1 = Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "    self.pool1 = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "    self.lrn1  = LayerNorm([64, 55, 55])\n",
        "\n",
        "    # feature extractor 1\n",
        "    self.conv2a = Conv2d(in_channels=64, out_channels=96, kernel_size=1, stride=1, padding=0)\n",
        "    self.conv2b = Conv2d(in_channels=96, out_channels=208, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool2a = MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2c = Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
        "    self.pool2b = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "    # feature extractor 2\n",
        "    self.conv3a = Conv2d(in_channels=272, out_channels=96, kernel_size=1, stride=1, padding=0)\n",
        "    self.conv3b = Conv2d(in_channels=96, out_channels=208, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool3a = MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3c = Conv2d(in_channels=272, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
        "    self.pool3b = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "    # fully connected layer \n",
        "    self.fc                  = Linear(in_features=272*13*13, out_features=7)\n",
        "    self.softmax             = LogSoftmax(dim=1)\n",
        "    self.batch_normalization = BatchNorm2d(272)\n",
        "    self.dropout             = Dropout(p=0.2)\n",
        "\n",
        "  def forward(self, x, dropout=True, batch_normalization=True):\n",
        "    \"\"\"\n",
        "    Perform a single step of forward propogation\n",
        "    \"\"\"\n",
        "    # block-1\n",
        "    conv1_out = F.relu(self.conv1(x))\n",
        "    pool1_out = self.pool1(conv1_out)\n",
        "    lrn1_out  = self.lrn1(pool1_out)\n",
        "\n",
        "    # feature extractor 1\n",
        "    # branch 1\n",
        "    conv2a_out = F.relu(self.conv2a(lrn1_out))\n",
        "    conv2b_out = F.relu(self.conv2b(conv2a_out))\n",
        "    # branch 2\n",
        "    pool2a_out = self.pool2a(lrn1_out)\n",
        "    conv2c_out = F.relu(self.conv2c(pool2a_out))\n",
        "    # concatenate both branches\n",
        "    concat2_out = torch.cat((conv2b_out, conv2c_out), 1)\n",
        "    pool2b_out  = self.pool2b(concat2_out)\n",
        "\n",
        "    # feature extractor 2\n",
        "    # branch 1\n",
        "    conv3a_out = F.relu(self.conv3a(pool2b_out))\n",
        "    conv3b_out = F.relu(self.conv3b(conv3a_out))\n",
        "    # branch 2\n",
        "    pool3a_out = self.pool3a(pool2b_out)\n",
        "    conv3c_out = F.relu(self.conv3c(pool3a_out))\n",
        "    # concatenate both branches\n",
        "    concat3_out = torch.cat((conv3b_out, conv3c_out), 1)\n",
        "    pool3b_out  = self.pool3b(concat3_out)\n",
        "\n",
        "    # dropout enabled\n",
        "    if dropout:\n",
        "      pool3b_out = self.dropout(pool3b_out)\n",
        "    \n",
        "    # batch normalization enabled\n",
        "    if batch_normalization:\n",
        "      pool3b_out = self.batch_normalization(pool3b_out)\n",
        "\n",
        "    pool3b_shape = pool3b_out.shape\n",
        "    pool3b_flat  = pool3b_out.reshape([-1, pool3b_shape[1] * pool3b_shape[2] * pool3b_shape[3]])\n",
        "\n",
        "    output = self.fc(pool3b_flat)\n",
        "    logits = self.softmax(output)\n",
        "\n",
        "    return logits\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ljF9f9Pflw"
      },
      "source": [
        "Utility functions to read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUcyA7ECPi7H"
      },
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "from matplotlib import image as im\n",
        "\n",
        "\n",
        "def data(*paths):\n",
        "  return DATA_FOLDER.joinpath(*paths)\n",
        "\n",
        "\n",
        "def read_file(img_file, label_file):\n",
        "  \"\"\"\n",
        "  Read and convert images to numpy arrays\n",
        "  \"\"\"\n",
        "  image = im.imread(img_file)\n",
        "\n",
        "  with open(label_file, \"r\") as file:\n",
        "        label = float(file.read())\n",
        "\n",
        "  return image, label\n",
        "\n",
        "\n",
        "def load_from_array():\n",
        "  \"\"\"\n",
        "  Load dataset from a specified folder\n",
        "  \"\"\"\n",
        "  x = np.load(data(\"x.npy\")).reshape(-1, 1, 224, 224)\n",
        "  y = np.load(data(\"y.npy\"))\n",
        "\n",
        "  return x, y\n",
        "\n",
        "\n",
        "def save_to_array():\n",
        "  \"\"\"\n",
        "  Save dataset to a specified folder\n",
        "  \"\"\"\n",
        "  with open(data(\"x.npy\"), \"wb\") as file:\n",
        "    np.save(file, x)\n",
        "\n",
        "  with open(data(\"y.npy\"), \"wb\") as file:\n",
        "    np.save(file, y)\n",
        "\n",
        "\n",
        "def load_dataset(use_existing = True):\n",
        "  \"\"\"\n",
        "  Return input and output variables from the\n",
        "  dataset\n",
        "  \"\"\"\n",
        "  if use_existing:\n",
        "    x, y = load_from_array()\n",
        "  \n",
        "  else:\n",
        "    data_dir = DATA_FOLDER\n",
        "    images   = []\n",
        "    labels   = []\n",
        "\n",
        "    for image_file in sorted(glob.glob(f\"{data_dir}/**/*.png\")):\n",
        "      image_path = os.path.dirname(image_file)\n",
        "      label_path = image_path.replace(\"images\", \"labels\")\n",
        "\n",
        "      if os.path.exists(label_path):\n",
        "        if not len(os.listdir(label_path)) == 0:\n",
        "          label_file = os.path.join(label_path, os.listdir(label_path)[0])\n",
        "\n",
        "          image, label = file_reader(image_file, label_file)\n",
        "          images.append(image)\n",
        "          labels.append(label)\n",
        "\n",
        "    x = np.stack(images, axis = 0).reshape(-1, 1, 224, 224)\n",
        "    y = np.stack(labels, axis = 0)\n",
        "\n",
        "    save_to_array(x, y)\n",
        "\n",
        "\n",
        "  print(\"Loaded datasets {} and {}\".format(x.shape, y.shape))\n",
        "  print(\"\")\n",
        "\n",
        "  return x, y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NjnmZZuU_Vu"
      },
      "source": [
        "Dataset utilities (Shuffle and convert to torch tensor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQRb5L9oVD08"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import shuffle as s\n",
        "\n",
        "\n",
        "def kfold(x, y, splits = 5, shuffle = True):\n",
        "  \"\"\"\n",
        "  Perform a K-fold split on the dataset\n",
        "  x -> Input variables from the dataset\n",
        "  y -> Output variables frm the dataset\n",
        "  \"\"\"\n",
        "  x, y = s(x, y)\n",
        "  kfold = KFold(n_splits = splits, shuffle = shuffle)\n",
        "\n",
        "  for train, test in kfold.split(x, y):\n",
        "    x_train, y_train = x[train], y[train]\n",
        "    x_test, y_test   = x[test], y[test]\n",
        "\n",
        "    yield x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "def convert_to_torch(x_train, y_train, x_test, y_test):\n",
        "  \"\"\"\n",
        "  Convert the train and test data to torch tensors\n",
        "  \"\"\"\n",
        "  # convert training images to a torch tensor\n",
        "  x_train = torch.from_numpy(x_train)\n",
        "  x_train = x_train.type(torch.FloatTensor)\n",
        "\n",
        "  # convert training labels to a torch tensor\n",
        "  y_train = y_train.astype(int)\n",
        "  y_train = torch.from_numpy(y_train)\n",
        "\n",
        "  # convert test images to torch tensor\n",
        "  x_test = torch.from_numpy(x_test)\n",
        "  x_test = x_test.type(torch.FloatTensor)\n",
        "\n",
        "  # convert testing labels to torch tensor\n",
        "  y_test = y_test.astype(int)\n",
        "  y_test = torch.from_numpy(y_test)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test\n"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}